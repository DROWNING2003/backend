from dotenv import load_dotenv
from agentflow.utils.crawl_github_files import checkout_to_commit, get_full_commit_history, get_or_clone_repository
from agentflow.flow import create_adaptive_flow
load_dotenv()

def test_adaptive_flow():
    """æµ‹è¯•è‡ªé€‚åº”çš„å…³å¡ç”Ÿæˆæµç¨‹"""
    print("\n=== æµ‹è¯•è‡ªé€‚åº”æµç¨‹ ===")
    repo_url = "https://github.com/zengyi-thinking/auto_mate_test4_complex"
    
    try:
        # å…‹éš†æˆ–è·å–ä»“åº“
        print("æ­£åœ¨å…‹éš†/è·å–ä»“åº“...")
        repo = get_or_clone_repository(repo_url, update_to_latest=False)
        tmpdirname = repo.working_dir
        checkout_to_commit(repo, commit_index=2)
        commits = get_full_commit_history(repo)
        # è®¾ç½®å…±äº«æ•°æ®
        shared = {
            "accumulated_changes":[],#ç´¯è®¡å·®å¼‚
            "fullcommits": commits,
            "max_commits_to_check":4, #æœ€å¤šcommit
            "commits_to_check":0, #å½“å‰ç´¯è®¡commit
            "tmpdirname": tmpdirname,
            "project_name": repo_url,
            "currentIndex": 2,  # ä»è¾ƒæ—©çš„æäº¤å¼€å§‹æµ‹è¯•
            "repo": repo,
            "language": "ä¸­æ–‡",
            "use_cache": True,
            "max_abstraction_num": 5,
        }
        
        print(f"å¼€å§‹ä»æäº¤ç´¢å¼• {shared['currentIndex']} è¿›è¡Œè‡ªé€‚åº”åˆ†æ...")
        
        # åˆ›å»ºå¹¶è¿è¡Œè‡ªé€‚åº”æµç¨‹
        flow = create_adaptive_flow()
        result = flow.run(shared)
        
        # è¾“å‡ºç»“æœ
        print("\n=== è‡ªé€‚åº”æµç¨‹æ‰§è¡Œç»“æœ ===")
        
        # æ£€æŸ¥ä¸Šä¸‹æ–‡è¯„ä¼°ç»“æœ
        context_eval = shared.get("context_evaluation", {})
        if context_eval:
            print(f"âœ… ä¸Šä¸‹æ–‡è¯„ä¼°å®Œæˆ:")
            print(f"   - æ˜¯å¦å€¼å¾—ä½œä¸ºå…³å¡: {context_eval.get('is_worthy', False)}")
            print(f"   - æœ€ç»ˆæäº¤ç´¢å¼•: {context_eval.get('final_commit_index', 'N/A')}")
            print(f"   - å¤„ç†çš„æäº¤æ•°: {context_eval.get('commits_processed', 'N/A')}")
            print(f"   - è¯„ä¼°åŸå› : {context_eval.get('evaluation', {}).get('reason', 'N/A')}")
            
            if context_eval.get('is_worthy'):
                print(f"   - å…³é”®æ¦‚å¿µ: {context_eval.get('evaluation', {}).get('key_concepts', [])}")
        
        # æ£€æŸ¥çŸ¥è¯†ç‚¹è¯†åˆ«ç»“æœ
        knowledge = shared.get("knowledge", [])
        if knowledge:
            print(f"\nğŸ“š è¯†åˆ«çš„çŸ¥è¯†ç‚¹ ({len(knowledge)}ä¸ª):")
            for i, concept in enumerate(knowledge, 1):
                print(f"   {i}. {concept.get('name', 'N/A')}")
                print(f"      æè¿°: {concept.get('description', 'N/A')[:100]}...")
        
        # æ£€æŸ¥ç”Ÿæˆçš„å…³å¡å†…å®¹
        level_content = shared.get("res")
        if level_content:
            print(f"\nğŸ¯ ç”Ÿæˆçš„å…³å¡å†…å®¹:")
            if isinstance(level_content, list):
                for i, level in enumerate(level_content, 1):
                    print(f"   å…³å¡ {i}: {level.get('name', 'N/A')}")
                    print(f"   æè¿°: {level.get('description', 'N/A')[:150]}...")
                    print(f"   è¦æ±‚: {level.get('requirements', 'N/A')[:100]}...")
                    print()
            else:
                print(f"   {level_content}")
        else:
            print("âŒ æœªç”Ÿæˆå…³å¡å†…å®¹")
            
        # æ£€æŸ¥æœ€ç»ˆçš„æäº¤ç´¢å¼•
        final_index = shared.get("currentIndex")
        print(f"\nğŸ“ æœ€ç»ˆæäº¤ç´¢å¼•: {final_index}")
        
    except Exception as e:
        print(f"âŒ è‡ªé€‚åº”æµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        
test_adaptive_flow()